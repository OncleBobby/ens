{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfdea75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, warnings, time, numpy, yaml\n",
    "sys.path.append(\"../src/\") # go to parent dir\n",
    "from data_access import get_X, get_y, get_train_test\n",
    "# from models import get_model_benchmark1, get_model_benchmark2, show_importance\n",
    "from models.model import Model\n",
    "from models.factory import ModelFactory\n",
    "from models.benchmark import Benchmark1, Benchmark2\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f766bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_X('train')\n",
    "train_scores = get_y()\n",
    "test_data = get_X('test')\n",
    "X_train, y_train, X_test, y_test, X_valid, y_valid, target = get_train_test(train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282620c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4401"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "benchmark1 = Benchmark1(X_train, y_train, X_valid, y_valid, train_scores)\n",
    "benchmark1.train()\n",
    "benchmark1.evaluate(X_test)\n",
    "# benchmark1.save(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b019d2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4742"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "benchmark2 = Benchmark2(X_train, y_train, X_valid, y_valid, train_scores)\n",
    "benchmark2.train()\n",
    "benchmark2.evaluate(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "225fc43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission=          ID  HOME_WINS  DRAW  AWAY_WINS\n",
      "0      12303          1     0          0\n",
      "1      12304          0     0          1\n",
      "2      12305          1     0          0\n",
      "3      12306          1     0          0\n",
      "4      12307          1     0          0\n",
      "...      ...        ...   ...        ...\n",
      "25363  37666          1     0          0\n",
      "25364  37667          1     0          0\n",
      "25365  37668          1     0          0\n",
      "25366  37669          1     0          0\n",
      "25367  37670          1     0          0\n",
      "\n",
      "[25368 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "benchmark2.save(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3560d3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission=          ID  HOME_WINS  DRAW  AWAY_WINS\n",
      "0      12303          1     0          0\n",
      "1      12304          0     0          1\n",
      "2      12305          1     0          0\n",
      "3      12306          1     0          0\n",
      "4      12307          1     0          0\n",
      "...      ...        ...   ...        ...\n",
      "25363  37666          1     0          0\n",
      "25364  37667          1     0          0\n",
      "25365  37668          1     0          0\n",
      "25366  37669          1     0          0\n",
      "25367  37670          1     0          0\n",
      "\n",
      "[25368 rows x 4 columns]\n",
      "submission=          ID  HOME_WINS  DRAW  AWAY_WINS\n",
      "0      12303          1     0          0\n",
      "1      12304          1     0          0\n",
      "2      12305          1     0          0\n",
      "3      12306          1     0          0\n",
      "4      12307          1     0          0\n",
      "...      ...        ...   ...        ...\n",
      "25363  37666          1     0          0\n",
      "25364  37667          1     0          0\n",
      "25365  37668          1     0          0\n",
      "25366  37669          1     0          0\n",
      "25367  37670          1     0          0\n",
      "\n",
      "[25368 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "params_by_name={\n",
    "    'benchmark2': {\n",
    "          'booster': 'gbtree',\n",
    "          'tree_method':'hist',\n",
    "          'max_depth': 8, \n",
    "          'learning_rate': 0.025,\n",
    "          'objective': 'multi:softprob',\n",
    "          'num_class': 2,\n",
    "          'eval_metric':'mlogloss'\n",
    "        },\n",
    "    'benchmark3': {\n",
    "          'booster': 'gblinear',\n",
    "          'tree_method':'hist',\n",
    "          'max_depth': 8, \n",
    "          'learning_rate': 0.025,\n",
    "          'objective': 'multi:softprob',\n",
    "          'num_class': 2,\n",
    "          'eval_metric':'mlogloss'\n",
    "        },\n",
    "}\n",
    "for name, params in params_by_name.items():\n",
    "    benchmark2 = Benchmark2(X_train, y_train, X_valid, y_valid, train_scores, params)\n",
    "    benchmark2.train()\n",
    "    benchmark2.evaluate(X_test)\n",
    "    benchmark2.name = name\n",
    "    benchmark2.save(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58fb2a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "gblinear_hist_mlogloss=0.4758 in 3.97s\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "def get_params(booster, tree_method, eval_metric='mlogloss'):\n",
    "    return {\n",
    "          'booster': booster,\n",
    "          'tree_method': tree_method,\n",
    "          'max_depth': 8, \n",
    "          'learning_rate': 0.025,\n",
    "          'objective': 'multi:softprob',\n",
    "          'num_class': 2,\n",
    "          'eval_metric':eval_metric\n",
    "        }\n",
    "# boosters = ['gbtree', 'gblinear', 'dart']\n",
    "boosters = ['gblinear']\n",
    "# tree_methods = ['auto', 'exact', 'approx', 'hist']\n",
    "tree_methods = ['hist']\n",
    "# eval_metrics = ['mphe', 'merror', 'mlogloss', 'auc']\n",
    "eval_metrics = ['mlogloss']\n",
    "for booster in boosters:\n",
    "    for tree_method in tree_methods:\n",
    "        for eval_metric in eval_metrics:\n",
    "          start = time.time()\n",
    "          name = f'{booster}_{tree_method}_{eval_metric}'\n",
    "          params = get_params(booster, tree_method, eval_metric)\n",
    "          benchmark2 = Benchmark2(X_train, y_train, X_valid, y_valid, train_scores, params)\n",
    "          benchmark2.train()\n",
    "          score = benchmark2.evaluate(X_test)\n",
    "          end = time.time()\n",
    "          print(f'{name}={score} in {numpy.round((end-start), 2)}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f2a0b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4754\n"
     ]
    }
   ],
   "source": [
    "name = 'benchmark3'\n",
    "with open('../confs/models.yaml', 'r') as file:\n",
    "    configurations = yaml.safe_load(file)\n",
    "factory = ModelFactory(configurations, X_train, y_train, X_valid, y_valid, train_scores)\n",
    "model = factory.get_model(name) \n",
    "model.train()\n",
    "print(model.evaluate(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c4d587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "benchmark3=0.4742 in 13.71s\n",
      "benchmark3=0.477 in 3.67s\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "with open('../confs/models.yaml', 'r') as file:\n",
    "    configurations = yaml.safe_load(file)\n",
    "factory = ModelFactory(configurations, X_train, y_train, X_valid, y_valid, train_scores)\n",
    "for model in factory.get_models():\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    score = model.evaluate(X_test)\n",
    "    end = time.time()\n",
    "    print(f'{name}={score} in {numpy.round((end-start), 2)}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
