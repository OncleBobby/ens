xgb_gblinear:
  class: models.xgboost_model.XgboostModel
  params:
    booster: gblinear
    tree_method: hist
    max_depth: 8 
    learning_rate: 0.025
    objective: "multi:softprob"
    num_class: 2
    eval_metric: mlogloss
xgb_classifier:
  class: models.xgboost_classifier_model.XgboostClassifierModel
  params:
    booster: gblinear
    tree_method: hist
    max_depth: 8 
    learning_rate: 0.025
    objective: "multi:softprob"
    num_class: 2
    eval_metric: mlogloss
catboost:
  class: models.catboost_model.CatBoostModel
  params:
    iterations: 1000
    devices: '0:1'
dummy:
  class: models.sklearn_model.SklearnModel
  params:
    class_name: sklearn.dummy.DummyClassifier
random_forest:
  class: models.sklearn_model.SklearnModel
  params:
    class_name: sklearn.ensemble.RandomForestClassifier
gradient_boosting:
  class: models.sklearn_model.SklearnModel
  params:
    class_name: sklearn.ensemble.GradientBoostingClassifier
ada_boost:
  class: models.sklearn_model.SklearnModel
  params:
    class_name: sklearn.ensemble.AdaBoostClassifier
# bagging:
#   class: models.sklearn_model.SklearnModel
#   params:
#     class_name: sklearn.ensemble.BaggingClassifier
extra_trees:
  class: models.sklearn_model.SklearnModel
  params:
    class_name: sklearn.ensemble.ExtraTreesClassifier
# decision_tree:
#   class: models.sklearn_model.SklearnModel
#   params:
#     class_name: sklearn.tree.DecisionTreeClassifier
hist_gradient_boosting:
  class: models.sklearn_model.SklearnModel
  params:
    class_name: sklearn.ensemble.HistGradientBoostingClassifier
# mlp:
#   class: models.sklearn_model.SklearnModel
#   params:
#     class_name: sklearn.neural_network.MLPClassifier
# kneighbors:
#   class: models.sklearn_model.SklearnModel
#   params:
#     class_name: sklearn.neighbors.KNeighborsClassifier
lightgbm:
  class: models.lightgbm_model.LightgbmModel
  params:
    learning_rate: 0.05
    max_depth: -5
    random_state: 42
    eval_metric: mlogloss
keras_relu_1:
  class: models.keras_model.KerasModel
  params:
    layers:
      - {'activation': 'relu', 'units': 10}
keras_relu_13:
  class: models.keras_model.KerasModel
  params:
    layers:
      - {'activation': 'relu', 'units': 15}
keras_relu_15:
  class: models.keras_model.KerasModel
  params:
    layers:
      - {'activation': 'sigmoid', 'units': 15}
      - {'activation': 'relu', 'units': 15}
      - {'activation': 'relu', 'units': 15}
      - {'activation': 'softmax', 'units': 15}
      - {'activation': 'relu', 'units': 15}
      - {'activation': 'relu', 'units': 15}
      - {'activation': 'relu', 'units': 15}

# sigmoid
# softmax
# softplus
# softsign
# selu
# tanh
# elu
# exponential
# leaky_relu
# silu
# gelu
# hard_sigmoid
# linear
# mish